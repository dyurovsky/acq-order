---
title: "Cross-linguistic variation in early word learning"
author: "Daniel Yurovsky, Mika Braginsky, Virginia Marchman, & Michael C. Frank"
date: "2015-05-10"
output:
  html_document:
  highlight: tango
theme: spacelab
---

Baby's First 10 Words Cross-linguistic

```{r setup, include=FALSE}
library(knitr)
options(digits = 2)
opts_chunk$set(message=FALSE, warning=FALSE, cache=TRUE)
```

Load required libraries.
```{r librares, cache=FALSE}
library(boot)
library(dplyr)
library(directlabels)
library(RMySQL)
library(tidyr)
library(bootstrap)
library(ggplot2)
library(RCurl)
library(magrittr)
library(readr)
library(stringr)
```

Get a script that provides interface functions for pulling data out of Wordbank.
```{r wordbank.funs, cache=FALSE}
url <- 'https://raw.githubusercontent.com/langcog/wordbank/master/shiny_apps/data_loading.R'
script <- getURL(url, ssl.verifypeer = FALSE)
eval(parse(text = script))
```

Connect to the Wordbank database.
```{r connect, cache=FALSE}
wordbank <- connect.to.wordbank("prod")
```

Load tables
```{r tables}
common.tables <- get.common.tables(wordbank)
instrument.tables <- get.instrument.tables(wordbank, common.tables)

admins <- get.administration.data(common.tables)
items <- get.item.data(common.tables)
```

Filter down to appropriate kids
```{r}
vocab.admins <- admins %>%
  select(data_id, language, form, age, sex, production) %>%
  filter(form == "WG", !is.na(sex), sex != "", age >= 8, age <=18)
```

Function that get's one language's data from wordbank
```{r}
get.language.data <- function(lang, vocab.data) {
  
  lang.table <- filter(instrument.tables, language==lang, form=="WG")$table[[1]]
  
  words <- items %>%
    filter(type == "word", language == lang, form == "WG") %>%
    select(definition, item.id, uni_lemma, category, lexical_category) %>%
    rename(item_id = item.id)
  
  lang.data <- lang.table %>%
    filter(basetable_ptr_id %in% vocab.data$data_id) %>%
    select_(.dots=c("basetable_ptr_id", words$item_id)) %>%
    as.data.frame %>% 
    gather(item_id, value, -basetable_ptr_id) %>%
    rename(data_id = basetable_ptr_id) %>%
    mutate(value = ifelse(is.na(value), "", value)) %>%
    left_join(vocab.data)
  
  return(left_join(lang.data, words))

  }
```

Get all data
```{r}
languages <- c("English", "Norwegian", "Croatian", 
               "Spanish","Swedish","Turkish")
all.data <- bind_rows(sapply(languages, 
                             function(lang) get.language.data(lang,vocab.admins),
                             simplify = FALSE))

get.lang.lemmas <- function(lang) unique(filter(all.data,
                                                language == lang)$uni_lemma)
common.lemmas <- Reduce(intersect, sapply(languages, get.lang.lemmas))
```

Compute cross-linguistic order
```{r}
order.data <- all.data %>%
  ungroup() %>%
  filter(uni_lemma %in% common.lemmas) %>%
  mutate(language = factor(language)) %>%
  group_by(language, uni_lemma,item_id) %>%
  summarise(produces = mean(value == "produces"),
            understands = mean(value == "produces" | value == "understands"),
            only.understands = mean(value == "understands")) %>%
  summarise(produces = max(produces),
            understands = max(understands),
            only.understands = max(only.understands)) %>%
  gather(measure, prop, produces, understands, only.understands) %>%
  group_by(language, measure) %>%
  mutate(order = rank(-prop))

unilemma.order <- order.data %>%
  group_by(measure, uni_lemma) %>%
  summarise(mean.order = mean(order),
            mean.prop = mean(prop))

order.mean.data <- order.data %>%
  left_join(unilemma.order) %>%
  mutate(held.out.prop = (mean.prop*length(languages) - prop)/
           (length(languages)-1),
         held.out.order = (mean.order*length(languages) - order)/
           (length(languages)-1)) %>%
  arrange(mean.order)

# Two baseline languages
# random.language <- order.mean.data %>%
#   filter(language == "English") %>%
#   ungroup() %>%
#   mutate(order = mean(order),
#          language = "Random")

# mean.language <- order.mean.data %>%
#   filter(language == "English") %>%
#   ungroup() %>%
#   mutate(order = mean.order,
#          language = "Mean")

baseline.order.data <- order.mean.data %>%
#  bind_rows(random.language) %>%
#  bind_rows(mean.language) %>%
 # mutate(order.diff = abs(order - held.out.order)) %>%
  mutate(order.diff = abs(order - mean.order)) %>%
  group_by(language, measure) %>%
  arrange(mean.order) %>%
  mutate(mean.order.diff = cumsum(order.diff))
```

Plot cross-linguistic acquisition order
```{r}
aq.order.data <- baseline.order.data %>%
  filter(measure == "produces")

quartz(width = 5.5,height = 3.3)
ggplot(aq.order.data, 
       aes(x = mean.order, y = mean.order.diff, 
           color = language, fill = language,
           label=language)) +
  geom_point(size=.8) +
  geom_smooth(method="loess")+
  geom_dl(method = list(dl.trans(x=x +.2), "last.bumpup", cex=.85))+ 
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_x_continuous(limits = c(0,210),breaks = seq(0,180,20),
                     name = "Mean Cross-Linguistic Acquisition Order")+
  scale_y_continuous(name = "Cumulative Difference from Mean Order")+
  theme_bw(base_size=11) +
  theme(panel.grid = element_blank(), legend.position="none")
```

Get frequency and phoneme data and merge.
```{r}
eng.phons <- read_delim('mrc.phons.txt',delim='\t')

eng.freqs <- read.csv('english.freqs.csv') %>%
  gather(word, count) %>%
  group_by(word) %>%
  summarize(frequency = mean(count)) %>%
  ungroup() %>%
  mutate(word = str_trim(tolower(gsub('\\.', ' ', word)))) %>%
  left_join(eng.phons)

eng.cats <- all.data %>%
  filter(language=="English") %>%
  select(uni_lemma,category,lexical_category) %>%
  distinct() %>%
  filter(uni_lemma %in% common.lemmas)

held.out.order.preds <- order.mean.data %>%
  filter(language == "English") %>%
  select(uni_lemma,measure,held.out.order,held.out.prop)

freqs.data <- order.mean.data %>%
 # select(-order,-mean.order,-lexical_category) %>%
  select(language,order,uni_lemma,measure) %>%
#  spread(language,prop) %>%
  spread(language,order) %>%
  left_join(held.out.order.preds) %>%
  left_join(eng.cats) %>%
  mutate(word = gsub(' \\(.*\\)', '', uni_lemma)) %>%
  left_join(eng.freqs) %>%
  filter(!is.na(frequency)) %>%
  group_by(measure) %>%
  arrange(English)
  #arrange(desc(English))

```

Construct acquisition order models 
```{r}
freqs.models <- freqs.data %>%
  do(lm.freq = lm(English ~ category + log(1000*frequency) + phones, 
                   data=.),
     lm.lang = lm(English ~ held.out.order, data=.))
  
get.model <- function(select.measure, model_type) {
  filter(freqs.models, measure == select.measure)[[model_type]][[1]]
}

get.prediction.lm.cor <- function(model_type, meas, group_data) {
    filtered_data <- filter(group_data, measure == meas)
    predicted = (predict(get.model(meas, model_type),
                                  newdata = filtered_data))
#     predicted = predict(get.model(meas, model_type),
#                               newdata = filtered_data)
    cor(filtered_data$English, predicted)
}

cum.model <- function(order.num) {
  
  order.model.data <- freqs.data %>%
    group_by(measure) %>%
    filter(row_number() <= order.num) %>%
#       filter(row_number() >= order.num - 10,
#              row_number() <= order.num + 10) %>%
    summarise(freq = get.prediction.lm.cor("lm.freq", unique(measure), .),
              lang = get.prediction.lm.cor("lm.lang", unique(measure), .)) %>%
  mutate(order.num = order.num)
}

cors <- bind_rows(sapply(seq(3, length(common.lemmas), 1),
                         cum.model, simplify = FALSE)) %>%
    gather(model,cor,freq,lang)
  

cors.plot.data <- cors %>%
  filter(measure == "produces") %>%
  select(-measure) %>%
  mutate(model = factor(model,levels = c("lang","freq"), 
                        labels = c("Cross-Linguistic","Distributional")))
```

Plot predictive models
```{r}
quartz(width = 4.5,height = 3.3)
ggplot(cors.plot.data, 
       aes(x = order.num, y = cor, 
           color = model, fill=model,label=model)) +
  geom_point(size=1) +
  geom_smooth(method="loess",span=.25)+
  geom_dl(method = list(dl.trans(x=x +.2), "last.bumpup", cex=.85))+ 
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  scale_x_continuous(limits = c(0,270),breaks = seq(0,180,20),
                     name = "English Acquisition Order")+
  scale_y_continuous(name = "Cumulative Correlation with English Order",
                     limits = c(-1,1),breaks=seq(-1,1,.25))+
  theme_bw(base_size=11) +
  theme(panel.grid = element_blank(), legend.position="none")
```


```{r}
prod.data <- filter(freqs.data, measure=="produces") %>%
  mutate(freq = inv.logit(predict(get.model("produces","lm.freq"))),
         nor = inv.logit(predict(get.model("produces","lm.lang")))) %>%
  gather(model,predicted,freq:nor) %>%
  group_by(measure,model) %>%
  mutate(resid = (English - predicted),
         order = rank(-English))

ggplot(prod.data, aes(x=order,y=resid,color=model))+
  geom_point() +
  theme_bw()

model <- lm(English~ frequency*category,data=filter(eng.data,measure=="produces"))
model2 <- lm(English~ Norwegian,data=filter(eng.data,measure=="produces"))

cor.test(filter(eng.data,measure=="produces")$order,filter(eng.data,measure=="produces")$freq.order,method="kendall")

```



```{r}
measure.diff <- order.mean.data %>%
  select(-mean.order, -prop) %>%
  spread(measure, order) %>%
  group_by(language, uni_lemma) %>%
  mutate(measure.diff = abs(produces - only.understands)) %>%
  group_by(language) %>%
  arrange(only.understands) %>%
  mutate(mean.measure.diff = cumsum(measure.diff))
```

```{r}
ggplot(measure.diff, aes(x = only.understands, y = mean.measure.diff, color = language)) +
  geom_point() +
  scale_color_brewer(palette = "Set1") +
  theme_bw() +
  theme(text = element_text(family = "Open Sans"))
```

```{r}
kids.by.lang <- vocab.data %>%
  group_by(language) %>%
  summarise(num.kids = n())

produced.data <- all.data %>%
  filter(value == "produces") %>%
  group_by(language,category,definition,gloss) %>%
  summarise(mean.age = mean(age),
            n = n()) %>%
  group_by(language) %>%
  left_join(kids.by.lang) %>%
  mutate(prop = n/num.kids) %>%
  arrange(desc(prop))
```

Top words
```{r}
top.words <- produced.data %>%
  slice(1:10) %>%
  select(language,gloss,prop,definition)

tab.words <- top.words %>%
  mutate(order = 1:10) %>%
  rowwise() %>%
  mutate(word = paste0(gloss," (",round(prop,digits=2),")")) %>%
  select(language,word,order) %>%
  spread(language,word) %>%
  select(-order)

kable(tab.words)
```

Models
```{r,}
model.words <- items %>%
  select(definition,language,gloss,category) %>%
  filter(language %in% unique(produced.data$language)) %>%
  left_join(produced.data) %>%
  rowwise() %>%
  mutate(n = as.numeric(ifelse(is.na(n),0,n)),
         prop = as.numeric(ifelse(is.na(prop),0,prop)),
         len = nchar(definition))

outputs <- NULL
components = c("count","zero")
params = c("len")

languages <- unique(model.words$language) 

predict.params <- expand.grid(language = languages,
                              component = components,
                              param = params)%>%
  arrange(language,component,param)

for(lang in languages) {
  
  hurd <- hurdle(n ~ len, 
                 data = filter(model.words,language==lang))
  


  for(component in components) {

    model.outs <- summary(hurd)$coefficients[as.character(component)][[1]]
    
    outputs <- rbind(outputs,model.outs[c("len"),
                                        c("Estimate", "Std. Error","Pr(>|z|)")])
  }
    
}
colnames(outputs) = c("estimate","se","p")

predict.params <- cbind(predict.params,outputs) %>%
  mutate(ci = 1.96*se) %>%
  mutate(component = factor(component, labels = c("Count Estimate", "Hurdle")))
```

Plot parameters
```{r, fig.width=5.5, fig.height=5}
ggplot(data = predict.params, 
       aes(x = language, y = estimate, fill=component))+
  geom_histogram(stat="identity",position="identity")+
  geom_linerange(aes(ymax =estimate+ci,
                      ymin = estimate-ci)) +
  facet_grid(component ~ param)+
  ylab("Parameter Estimate (+/- 95% CI)")+
  xlab("Dataset") + 
  geom_hline(yintercept=0, lty=2,size=.7) + 
  #scale_color_brewer(name="Dataset",palette="Set1")+
  scale_fill_brewer(palette="Set1")+
  theme_bw(base_size=14) +
  theme(legend.position="none",
        axis.text.x = element_text(angle=-45, hjust = 0),
        axis.title.x = element_text(vjust=-0.5),
        panel.grid = element_blank())
```



Look at age distributions
```{r,fig.width=3,fig.height=8}
# all.by.age <- vocab.admins %>%
#   group_by(language,age) %>%
#   summarise(all.n = n())
# 
# age.hists <- vocab.data %>%
#   group_by(language,age) %>%
#   summarise(n = n()) %>%
#   left_join(all.by.age) %>%
#   mutate(prop = n/all.n) %>%
#   mutate(prop = prop/sum(prop))
# 
# ggplot(data = age.hists,aes(x=age,y=prop)) +
#   facet_grid(language ~ .) +
#   geom_histogram(stat="identity",
#                  fill="steelblue") +
#   geom_vline(xintercept=12,linetype="dashed")+
#   scale_x_continuous(limits=c(8,16),breaks=seq(8,16),name="Age (months)") +
#   scale_y_continuous(name = "Proportion of Children") +
#   theme_bw()+
#   theme(panel.grid=element_blank()) 
```
